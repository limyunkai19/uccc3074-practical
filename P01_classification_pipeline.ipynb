{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P01: The Classification Pipeline\n",
    "\n",
    "In this practical, you will practice putting together a simple classification pipeline. We shall begin with k-Nearest Neighbor. The goals of this practical are as follows:\n",
    "\n",
    "1. Understand the basic machine learning (classification) pipeline \n",
    "2. Understand how to perform hyperparameter tuning\n",
    "3. Develop proficiency in writing efficient vectorized code with numpy\n",
    "4. implement and apply a k-Nearest Neighbor (kNN) classifier\n",
    "\n",
    "The kNN classifier consists of two stages:\n",
    "\n",
    "* During **training**, the classifier simply remembers the training  it\n",
    "* During **testing**, kNN classifies every test image by comparing to all training images and transfering the labels of the k most similar training examples\n",
    "\n",
    "Finally, the value of k will be **cross-validated** to determine the best k settings for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib import cifar10\n",
    "from lib.common import show_thumbnails\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the plot\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "# set to automatic reload\n",
    "%load_ext autoreload             \n",
    "%autoreload 2           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = cifar10.load_data (r'.\\data\\cifar-10-batches-py')\n",
    "classes = cifar10.get_classes()\n",
    "num_classes = len(classes)\n",
    "\n",
    "print('classes:', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the CIFAR10 dataset\n",
    "\n",
    "CIFAR-10  is an established computer-vision dataset used for object recognition. It is a subset of the 80 million tiny images dataset and consists of 60,000 32x32 color images containing one of 10 object classes, with 6000 images per class.\n",
    "\n",
    "Let's explore the dataset to understand it. First, we visualize some examples from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_thumbnails (X_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the type of X_train?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the type of y_train?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the size of the training samples?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the dimension of each sample? What does it mean?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the size of the testing samples?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many classes are there? What are all the labels for y_train? How many samples are there for each class in the training set?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many samples are there for each class in the testing set?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Visualize the first record of X_train and show its label ** \n",
    "<br> Tips: Refer to the function `show_thumbnails` for clues (Commands: `plt.figure`, `plt.imshow`, `plt.title`, and `plt.show`). Remember to reshape your image to the appropriate shape before displaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our data\n",
    "\n",
    "We would now like to classify the test data with the kNN classifier. We shall implement functions to (1) train the model and (2) predict the model.\n",
    "\n",
    "For the following experiment, for more efficient code execution, we shall subsample only 5000 training samples and 500 test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_test = 500\n",
    "num_training = 5000\n",
    "\n",
    "mask = list(range(num_training))\n",
    "X_train = X_train[mask]\n",
    "y_train = np.take(y_train, mask)\n",
    "\n",
    "mask = list(range(num_test))\n",
    "X_test = X_test[mask]\n",
    "y_test = np.take(y_test, mask)\n",
    "\n",
    "print ('Number of training samples:', len(X_train))\n",
    "print ('Number of testing samples:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1: Reshape the sample**\n",
    "\n",
    "Each sample has a size of (32,32,3) whereas the whole training set has a size of (5000, 32, 32, 3) and the testing set (500, 32, 32, 3). Reshape the image data (each sample) into rows such that the size of the training and testing set are reshaped to (5000, 3072) and (500, 3072) respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here: Reshape the image data into rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "**Exercise 2: Implement the `train` function**: \n",
    "\n",
    "First, open `lib/knn_classifier.py` and implement the function **`train`** to train the classifier. For k-nearest neighbors, this is just memorizing the training data. \n",
    "\n",
    "If your function is successfully implemented, the following code would show that 5000 samples and labels are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lib.knn_classifier import KNN\n",
    "classifier = KNN()\n",
    "classifier.train(X_train, y_train)\n",
    "print('Saved', len(classifier.X_train), 'samples')\n",
    "print('Saved', len(classifier.y_train), 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "We would now like to classify the test data with the kNN classifier. Recall that we can break down this process into two steps:\n",
    "\n",
    "1. First we must compute the distances between all test examples and all train examples.\n",
    "2. Given these distances, for each test example we find the k nearest examples and have them vote for the label\n",
    "\n",
    "**Exercise 3: Compute the distance matrix between all training and test samples (non-vectorized version).**\n",
    "\n",
    "Lets begin with computing the distance matrix between all training and test examples. For example, if there are Ntr training examples and Nte test examples, this stage should result in a Nte x Ntr matrix where each element (i,j) is the distance between the i-th test and j-th train example.\n",
    "\n",
    "Implement the function **`compute_distances_two_loops`** in `lib/knn_classifier.py`. The function uses a very *inefficient* double for loop over all pairs of (test, train) examples and computes the distance matrix one element at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dists = classifier.compute_distances_two_loops(X_test) # compute the distance between the test set and training set\n",
    "print('Shape of dists =', dists.shape)       # expecting a shape of 500 by 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows the distance between the 1st training and testing samples as well as the last samples. Expected answer = 3803 and 8041. \n",
    "\n",
    "Notes: If you get an answer of 565.86 and 576.74 respectively, the distance computed by `compute_distances_two_loops` is not correct. Debug your code and make the necessary changes to make it work.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(dists[0][0])      \n",
    "print(dists[-1][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4: Implement the function `predict`**\n",
    "\n",
    "Implement the function **`predict`** in `lib/knn_classifier.py` and run the code below: Use k = 1 (which is Nearest Neighbor). You should expect the predicted label for the first 5 samples are [4 9 8 8 4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test, which_ver= 2, k=1)\n",
    "print(y_test_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5: Implement the function to compute the accuracy of predict_labels**\n",
    "\n",
    "The accuracy value is simply You should expect to see approximately 27.4% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy (pred, actual, printMsg=True):\n",
    "    \n",
    "    # Put your code here     \n",
    "        \n",
    "    if printMsg:\n",
    "        print('Test accuracy: Got {:d} / {:d} correct => accuracy: {:.1f}%'.format(num_correct, len(actual), accuracy*100))\n",
    "        \n",
    "    return num_correct, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_correct, accuracy = get_accuracy(y_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to use k = 5. You should expect a slightly better performance with k = 5 (approximately 27.8% accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict(X_test, k=5)\n",
    "num_correct, accuracy = get_accuracy(y_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Coursework Assignment 1 (5 marks)\n",
    "\n",
    "** Submission**:\n",
    "\n",
    "This is the first coursework assignment which extends this practical. Complete this section and upload the following files to WBLE by 04 Feb 2018. \n",
    "* `knn_classifier.py`\n",
    "* `P01_classification_pipeline.ipynb`\n",
    "---\n",
    "\n",
    "**Task 1: Partial vectorization of the distance matrix**\n",
    "\n",
    "Speed up distance matrix computation by using partial vectorization with **one loop**. Implement the function **`compute_distances_one_loop`** in `lib/knn_classifier.py` and run the code below.\n",
    "\n",
    "To ensure that our vectorized implementation is correct, we make sure that it agrees with the naive implementation. There are many ways to decide whether two matrices are similar; one of the simplest is the Frobenius norm. In case you haven't seen it before, the Frobenius norm of two matrices is the square root of the squared sum of differences of all elements; in other words, reshape  the matrices into vectors and compute the Euclidean distance between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dists_one = classifier.compute_distances_one_loop(X_test)\n",
    "\n",
    "# check that the distance matrix agrees with the one we computed before:\n",
    "difference = np.linalg.norm(dists - dists_one, ord='fro')\n",
    "print('Difference was: {:.2f}'.format(difference))\n",
    "if difference < 0.001:\n",
    "    print('Congrats: the distance matrices are the same')\n",
    "else:\n",
    "    print('Opps! The distance matrices are different. There is some problem with your implementation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Task 2: Full vectorization of the distance matrix**\n",
    "\n",
    "Implement the fully vectorized version with **no loop** inside **`compute_distances_no_loops`** in `lib/knn_classifier.py` and run the code.\n",
    "\n",
    "Hint:\n",
    "\n",
    "Consider the following vectors:\n",
    "``` Python\n",
    "a = [[a1 a2 a3], \n",
    "     [a4 a5 a6]]\n",
    "\n",
    "b = [[b1 b2 b3],\n",
    "     [b4 b5 b6],\n",
    "     [b7 b8 b9]]\n",
    "       \n",
    "dist(a,b) = [[d1 d2, d3],\n",
    "             [d4,d5, d6]] \n",
    "```\n",
    "Let's derive the l2 distance between the first samples for `a` and `b`:\n",
    "\n",
    "`d1` = l2 distance between `[a1, a2, a3]` and `[b1, b2, b3]`\n",
    "<br> = $\\sqrt{(a_1-b_1)^2 + (a_2-b_2)^2 + (a_3-b_3)^2)}$ \n",
    "<br> = $\\sqrt{(a_1^2 + a_2^2 + a_3^2) + (b_1^2 + b_2^2 + b_3^2) - 2*(a_1b_1 + a_2b_2, + a_3b_3)}$       ...(EQ1)\n",
    "\n",
    "The solution is based on the generalization of EQ1 to all items in the distance matrix. The implementation involves two broadcast sum (to get the first two terms for all elements) and one matrix multiplication (to get the third term for all elements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dists_two = classifier.compute_distances_no_loops(X_test)\n",
    "\n",
    "# check that the distance matrix agrees with the one we computed before:\n",
    "difference = np.linalg.norm(dists - dists_two, ord='fro')\n",
    "print('Difference was: {:.2f}'.format(difference))\n",
    "if difference < 0.001:\n",
    "    print('Congrats: the distance matrices are the same')\n",
    "else:\n",
    "    print('Opps! The distance matrices are different. There is some problem with your implementation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have implemented three versions of compute distance. Let's compare them and see the difference in speed between them. You should see significantly faster performance with the fully vectorized implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's compare how fast the implementations are\n",
    "def time_function(f, *args):\n",
    "    \"\"\"\n",
    "    Call a function f with args and return the time (in seconds) that it took to execute.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    tic = time.time()\n",
    "    f(*args)\n",
    "    toc = time.time()\n",
    "    return toc - tic\n",
    "\n",
    "two_loop_time = time_function(classifier.compute_distances_two_loops, X_test)\n",
    "print('Non-vectorized (two loops) version took {:.2f} seconds'.format(two_loop_time))\n",
    "\n",
    "one_loop_time = time_function(classifier.compute_distances_one_loop, X_test)\n",
    "print('Partially vectorized (one loop) version took %f seconds'.format(one_loop_time))\n",
    "\n",
    "no_loop_time = time_function(classifier.compute_distances_no_loops, X_test)\n",
    "print('Fully vectorized (no loop) version took %f seconds'.format(no_loop_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Task 3: Hyperparameter optimization**\n",
    "\n",
    "We have implemented the k-Nearest Neighbor classifier but we set the value k = 5 arbitrarily. We will now determine the best value of this hyperparameter with cross-validation.  In the following, we shall use grid search to look for the best `k` hyperparameter.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: \n",
    "In general, *random search* works better than a *grid search* for hyperparameter optimization. Why do we use **grid search** but not random search here? \n",
    "\n",
    "Answer:\n",
    "\n",
    "*___________Put your answer here________________*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, write the algorithm to perform the cross validation. Use 5 folds and evaluate across k = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]. Then find the best hyperparameter to use for the testing set.\n",
    "\n",
    "Store your result into the dictionary `k_accuracies`. It should contain 10 items corresponding to  the evaluated k settings. Each item should store num_folds (i.e., 5) values. Each value corresponds to the kNN accuracy value on a particular fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]        #hyperparameter to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_accuracies = dict()                                    \n",
    "for k in k_choices:\n",
    "    k_accuracies[k] = []                                  \n",
    "    \n",
    "knn_classifier = KNN()\n",
    "\n",
    "################################################################################\n",
    "# ToDo:                                                                        #\n",
    "# Perform k-fold cross validation to find the best value of k. For each        #\n",
    "# possible value of k, run the k-nearest-neighbor algorithm num_folds times.   #\n",
    "#                                                                              #\n",
    "# Use scikit-learn's StratifiedKFold to perform the stratification.            #\n",
    "#                                                                              #\n",
    "# Store the accuracies for all fold and all values of k into the               #\n",
    "# k_accuracies dictionary.                                                     #\n",
    "#                                                                              #\n",
    "# To make your code more efficient, you can avoid computing the distance       #\n",
    "# matrix repeatedly                                                            #\n",
    "################################################################################\n",
    "\n",
    "# Put your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the accuracies for different k and fold \n",
    "for k in k_choices:\n",
    "    print(\"k =\", k, \", accuracies=\", [\"{:.4f}\".format(accuracy) for accuracy in k_accuracies[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the raw observations\n",
    "for k in k_choices:\n",
    "    accuracies = k_accuracies[k]\n",
    "    plt.scatter([k] * len(accuracies), accuracies)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(k_accuracies.items())])\n",
    "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Task 4: Evaluate on test set**\n",
    "\n",
    "Based on the cross-validation results above, choose the best value for k, retrain the classifier using all the training data, and test it on the test data. \n",
    "\n",
    "First get the best hyperparameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, evaluate your testset. You should be able to get above 28% accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu]",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
